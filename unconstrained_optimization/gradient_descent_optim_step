import numpy as np
import matplotlib.pyplot as plt

from utils import rosenbrock, rosenbrock_prime, Arrow3D, _arrow3D

def gradient_descent_variable_step(x_init, tolerance=1e-5, max_iteration=10000):
    """
    Use the gradient descent method with variable step to find the minimum of a function f in R2.
    """

    x = x_init
    iterates = [x_init]
    residual = 2 * tolerance
    learning_rate = 1e-3

    while np.linalg.norm(residual) > tolerance and len(iterates) < max_iteration:
        delta = - learning_rate * np.array(rosenbrock_prime(x))
        x = x + delta
        residual = np.linalg.norm(x - iterates[-1])
        iterates.append(x)
        learning_rate = 1 / (len(iterates) + 1)

    return iterates, x

def golden_section_search():
    pass